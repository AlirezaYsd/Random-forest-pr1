# -*- coding: utf-8 -*-
"""RF_practice_tr403.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-ormmFkej-bBsOiBDn8SH7OHhmsx03cG
"""

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

df = pd.read_excel('/content/drive/MyDrive/dataset/HSIS.xlsx')

df.head()

df = df[df['CAUSE1'] == '1']
print(df.shape)

df.head()

df.drop('CAUSE1', axis=1, inplace=True)
df.head()

df_copy = df.copy()

df_copy.describe()

df_copy.drop(['ACCYR', 'ACC_DATE'],axis=1, inplace=True)
df_copy.isna().sum()

df_copy.info()

unimportant_list = ['cnty_rte', 'CASENO', 'CCC']
df_copy.drop(unimportant_list, axis=1, inplace=True)

df_copy.info()

import seaborn as sns
import matplotlib.pyplot as plt
sns.set()

sns.countplot(x='SEVERITY',data=df_copy, color='steelblue')
plt.xticks(rotation=90)
plt.ylabel('Records')
plt.xlabel('SEVERITY')
plt.title('Number of Records for each SEVERITY type')
plt.show()

cat_features = ['ACCTYPE', 'WEATHER1', 'WEATHER2', 'RDSURF', 'LIGHT', 'MED_TYPE', 'ACCESS', 'RURURB', 'FED_AID', 'SURF_TYP', 'DRV_SEX', 'CONTRIB1', 'CONTRIB2', 'CAUSE', 'rte_type']
counter = 0
for i in cat_features:
  sns.countplot(x=i,data=df_copy, color='steelblue')
  plt.xticks(rotation=90)
  plt.ylabel('Records')
  plt.xlabel(i)
  plt.title(f'Number of Records for each {i}')
  plt.savefig(f'pic{counter}.png')
  plt.show()
  counter += 1

print(df_copy['FED_AID'].value_counts())

df_copy.drop(['WEATHER2','CONTRIB2'], axis=1, inplace=True)

df_copy.drop('CAUSE', axis=1, inplace=True)

num_features = []
for i in df_copy.columns.values:
  if i not in cat_features:
    num_features.append(i)

df_copy.head()

df_copy.shape

df_copy1 = df_copy

for i in cat_features:
  if i == 'CAUSE' or i == 'WEATHER2' or i == 'CONTRIB2':
    cat_features.remove(i)

print(len(cat_features))

cat_features

df_copy.info()

for i in cat_features:
  if i != 'CAUSE':
    print(f"{i} : {df_copy1[i].unique()}")

df_copy1['FED_AID'].unique()

df_copy1['FED_AID'] = df_copy1['FED_AID'].apply(lambda x: '0' if x == 0 else x)

df_copy1['FED_AID'].unique()

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()

df_copy1['FED_AID'] = encoder.fit_transform(df_copy1['FED_AID'])
df_copy1['DRV_SEX'] = encoder.fit_transform(df_copy1['DRV_SEX'])
df_copy1['CONTRIB1'] = encoder.fit_transform(df_copy1['CONTRIB1'])
df_copy1['rte_type'] = encoder.fit_transform(df_copy1['rte_type'])

for i in cat_features:
  if i != 'CAUSE':
    print(f"{i} : {df_copy1[i].unique()}")

df_copy1['SURF_TYP'].unique()

df_copy1['SURF_TYP'] = df_copy1['SURF_TYP'].apply(lambda x: '0' if x == 0 else x)

df_copy1['SURF_TYP'].unique()

df_copy1['SURF_TYP'] = encoder.fit_transform(df_copy1['SURF_TYP'])

for i in cat_features:
  if i != 'CAUSE':
    print(f"{i} : {df_copy1[i].unique()}")

df_copy1.info()

cat_features.remove('CAUSE')

cat_features

for i in cat_features:
  if i != 'FED_AID' or i != 'DRV_SEX' or  i != 'CONTRIB1' or i != 'rte_type':
    df_copy1[i] = encoder.fit_transform(df_copy1[i])

for i in cat_features:
  if i != 'CAUSE':
    print(f"{i} : {df_copy1[i].unique()}")

df_copy1.info()

sns.lineplot(data=df_copy1, x='SEVERITY', y='milepost')

for i in num_features:
  sns.scatterplot(data=df_copy1, x='SEVERITY', y=i)
  plt.show()

for i in num_features:
  sns.lineplot(data=df_copy1, x='SEVERITY', y=i)
  plt.show()

X = df_copy1.drop(['SEVERITY'], axis=1)

y = df_copy1['SEVERITY']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)

X_train.shape, X_test.shape

from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(random_state=0)


rfc.fit(X_train, y_train)


y_pred = rfc.predict(X_test)


from sklearn.metrics import accuracy_score

print('Model accuracy score with 10 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

rfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)


rfc_100.fit(X_train, y_train)

y_pred_100 = rfc_100.predict(X_test)

print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))

clf = RandomForestClassifier(n_estimators=100, random_state=0)

clf.fit(X_train, y_train)

feature_scores = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)

feature_scores

feature_scores.to_excel('output.xlsx')

X_step1 = df_copy1.drop(['SEVERITY', 'FED_AID'], axis=1)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_step1, y, test_size = 0.33, random_state = 42)

clf = RandomForestClassifier(random_state=0)


clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)


print('Model accuracy score with FED_AID variable removed : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

X_step2 = df_copy1.drop(['SEVERITY', 'FED_AID', 'rte_type', 'ACCESS'], axis=1)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_step2, y, test_size = 0.33, random_state = 42)

clf = RandomForestClassifier(random_state=0)


clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)


print('Model accuracy score with FED_AID, rte_type, ACCESS variable removed : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

X_step3 = df_copy1.drop(['SEVERITY', 'FED_AID', 'rte_type', 'ACCESS', 'RDSURF', 'RURURB'], axis=1)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_step3, y, test_size = 0.33, random_state = 42)

clf = RandomForestClassifier(random_state=0)


clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)


print('Model accuracy score with FED_AID, rte_type, ACCESS, RDSURF, RURURB variable removed : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

print('Confusion matrix\n\n', cm)

from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report, ConfusionMatrixDisplay

confusion_matrix_log = confusion_matrix(y_test, y_pred)
cm_display_log = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_log, display_labels = ['property damage(0)','Fatal(1)','Visible injury(2)','Severe injury(3)','Complain of pain(4)'])
cm_display_log.plot(cmap=plt.cm.Blues)

plt.savefig('logcm.png', bbox_inches='tight', dpi=300)
plt.show()

print(classification_report(y_test, y_pred))

import xgboost
from xgboost import XGBClassifier

boost = XGBClassifier(random_state=23)
boost.fit(X_train, y_train)

pred_boost = boost.predict(X_test)
pred_boost

print(classification_report(y_test, pred_boost))

# Get and reshape confusion matrix data
matrix = confusion_matrix(y_test, y_pred)
matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]

# Build the plot
plt.figure(figsize=(16,7))
sns.set(font_scale=1.4)
sns.heatmap(matrix, annot=True, annot_kws={'size':10},
            cmap=plt.cm.Greens, linewidths=0.2)

# Add labels to the plot
class_names = ['property damage(0)','Fatal(1)','Visible injury(2)','Severe injury(3)','Complain of pain(4)']
tick_marks = np.arange(len(class_names))
tick_marks2 = tick_marks + 0.5
plt.xticks(tick_marks, class_names, rotation=25)
plt.yticks(tick_marks2, class_names, rotation=0)
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.title('Confusion Matrix for Random Forest Model')
plt.show()

import pickle

save_path = "model.pkl"

with open(save_path, 'wb') as file:
    pickle.dump(clf, file)

print("Model saved as pickle file.")

